{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "l0TCn0IgBcVR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = load_model('/content/autoencoder_model.h5')\n",
        "encoder_model = load_model('/content/encoder_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlXOk24eCT5E",
        "outputId": "13776772-9de7-4900-d659-eb602d8d773f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the models manually\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
        "encoder_model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "metadata": {
        "id": "2S5csk3hMEU9"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('SAML-D_cleaned_final.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DV_5JXjfHnF_",
        "outputId": "49d2ce52-146b-49eb-9c75-74772860f1be"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-74-434d0fa35970>:1: DtypeWarning: Columns (47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('SAML-D_cleaned_final.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['Unnamed: 0', 'risk_score'])"
      ],
      "metadata": {
        "id": "_AlzsRbyHqV0"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify boolean columns and convert them to integers\n",
        "bool_columns = df.select_dtypes(include=['bool', 'object']).columns"
      ],
      "metadata": {
        "id": "-2ZcyL5vJQTz"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in bool_columns:\n",
        "    # Convert boolean-like object columns to actual boolean type first\n",
        "    if df[col].dtype == 'object':\n",
        "        df[col] = df[col].map({'True': True, 'False': False, 'true': True, 'false': False})\n",
        "\n",
        "    # Replace NaN values with a default value (e.g., False or 0)\n",
        "    df[col].fillna(False, inplace=True)\n",
        "\n",
        "    # Convert boolean columns to integers\n",
        "\n",
        "    df[col] = df[col].astype(int)"
      ],
      "metadata": {
        "id": "pAJQKrDUJTkg"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if df.isnull().values.any():\n",
        "    df = df.dropna()"
      ],
      "metadata": {
        "id": "xNDBwWYbJXoS"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting the X as everything except the target\n",
        "X = df.drop(columns=['Is_Laundering'])\n",
        "y = df['Is_Laundering']"
      ],
      "metadata": {
        "id": "86qYcHgMJgPA"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SCale the data\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "3xfVnIbhJm4V"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ZQdL7vchJo7C"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_risk_score(row):\n",
        "    score = 0\n",
        "\n",
        "    # High-Risk Countries\n",
        "    if row['high_risk_countries']:\n",
        "        score += 20  # Assigning a significant score\n",
        "\n",
        "    # Transaction Amount\n",
        "    amount_score = min(row['Amount'] / 1000, 20)  # Normalizing and capping at 20\n",
        "    score += amount_score\n",
        "\n",
        "    # Laundering Types (assuming specific feature names)\n",
        "    laundering_types = [\n",
        "        'Laundering_type_Behavioural_Change_1',\n",
        "        'Laundering_type_Behavioural_Change_2',\n",
        "        'Laundering_type_Bipartite',\n",
        "        'Laundering_type_Cash_Withdrawal',\n",
        "        'Laundering_type_Cycle',\n",
        "        'Laundering_type_Deposit-Send',\n",
        "        'Laundering_type_Fan_In',\n",
        "        'Laundering_type_Fan_Out','Laundering_type_Gather-Scatter',\n",
        "        'Laundering_type_Layered_Fan_In','Laundering_type_Layered_Fan_Out',\n",
        "        'Laundering_type_Normal_Cash_Deposits','Laundering_type_Normal_Cash_Withdrawal',\n",
        "        'Laundering_type_Normal_Fan_In','Laundering_type_Normal_Fan_Out',\n",
        "        'Laundering_type_Normal_Foward','Laundering_type_Normal_Group',\n",
        "        'Laundering_type_Normal_Mutual','Laundering_type_Normal_Periodical',\n",
        "        'Laundering_type_Normal_Plus_Mutual',\n",
        "       'Laundering_type_Normal_Small_Fan_Out',\n",
        "       'Laundering_type_Normal_single_large', 'Laundering_type_Scatter-Gather',\n",
        "       'Laundering_type_Single_large', 'Laundering_type_Smurfing',\n",
        "       'Laundering_type_Stacked Bipartite', 'Laundering_type_Structuring',\n",
        "\n",
        "        # Add more as per your model's expectations\n",
        "    ]\n",
        "\n",
        "    for laundering_type in laundering_types:\n",
        "        if row[laundering_type]:\n",
        "            # Adjust scoring logic based on each laundering type\n",
        "            if laundering_type == 'Laundering_type_Smurfing':\n",
        "                score += 15\n",
        "            elif laundering_type == 'Laundering_type_Scatter-Gather':\n",
        "                score += 15\n",
        "\n",
        "    # Time of Transaction\n",
        "    if row['Hour'] < 6 or row['Hour'] > 22:\n",
        "        score += 10  # Transactions at odd hours get a higher score\n",
        "\n",
        "    return score\n"
      ],
      "metadata": {
        "id": "cyozh4PbJrDm"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process features and calculate risk score\n",
        "def process_features_and_calculate_risk(features):\n",
        "    # Convert features dictionary to DataFrame\n",
        "    features_df = pd.DataFrame([features])\n",
        "\n",
        "    # Normalize the features\n",
        "    features_scaled = scaler.transform(features_df)\n",
        "\n",
        "    # Pass through the encoder to get the reduced features\n",
        "    reduced_features = encoder_model.predict(features_scaled)[0]\n",
        "\n",
        "    # Calculate risk score\n",
        "    risk_score = calculate_risk_score(features)\n",
        "\n",
        "    return risk_score, reduced_features\n"
      ],
      "metadata": {
        "id": "qJrXQEmEJue4"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = {\n",
        "    'Sender_account': 12345,\n",
        "    'Receiver_account': 67890,\n",
        "    'Amount': 1000,\n",
        "    'Year': 2024,\n",
        "    'Month': 7,\n",
        "    'Day': 2,\n",
        "    'Hour': 12,\n",
        "    'Minute': 30,\n",
        "    'Second': 15,\n",
        "    'Payment_currency_Albanian lek':0,\n",
        "    'Payment_currency_Dirham':1,\n",
        "    'Payment_currency_Euro':0,\n",
        "    'Payment_currency_Indian rupee':0,\n",
        "    'Payment_currency_Mexican Peso':1,\n",
        "    'Payment_currency_Moroccan dirham':0,\n",
        "    'Payment_currency_Naira':0,\n",
        "    'Payment_currency_Pakistani rupee':0,\n",
        "    'Payment_currency_Swiss franc':0,\n",
        "    'Payment_currency_Turkish lira':1,\n",
        "    'Payment_currency_UK pounds':0,\n",
        "    'Payment_currency_US dollar':0,\n",
        "    'Payment_currency_Yen':0,\n",
        "    'Received_currency_Albanian lek':0,\n",
        "    'Received_currency_Dirham':0,\n",
        "    'Received_currency_Euro':0,\n",
        "    'Received_currency_Indian rupee':1,\n",
        "    'Received_currency_Mexican Peso':0,\n",
        "    'Received_currency_Moroccan dirham':0,\n",
        "    'Received_currency_Naira':0,\n",
        "    'Received_currency_Pakistani rupee':0,\n",
        "    'Received_currency_Swiss franc':0,\n",
        "    'Received_currency_Turkish lira':0,\n",
        "    'Received_currency_UK pounds':0,\n",
        "    'Received_currency_US dollar':0,\n",
        "    'Received_currency_Yen':0,\n",
        "    'Sender_bank_location_Albania':0,\n",
        "    'Sender_bank_location_Austria':1,\n",
        "    'Sender_bank_location_France':0,\n",
        "    'Sender_bank_location_Germany':0,\n",
        "    'Sender_bank_location_India':0,\n",
        "    'Sender_bank_location_Italy':0,\n",
        "    'Sender_bank_location_Japan':0,\n",
        "    'Sender_bank_location_Mexico':0,\n",
        "    'Sender_bank_location_Morocco':0,\n",
        "    'Sender_bank_location_Netherlands':0,\n",
        "    'Sender_bank_location_Nigeria':0,\n",
        "    'Sender_bank_location_Pakistan':0,\n",
        "    'Sender_bank_location_Spain':0,\n",
        "    'Sender_bank_location_Switzerland':0,\n",
        "    'Sender_bank_location_Turkey':0,\n",
        "    'Sender_bank_location_UAE':0,\n",
        "    'Sender_bank_location_UK':0,\n",
        "    'Sender_bank_location_USA':0,\n",
        "    'Receiver_bank_location_Albania':0,\n",
        "    'Receiver_bank_location_Austria':0,\n",
        "    'Receiver_bank_location_France':0,\n",
        "    'Receiver_bank_location_Germany':0,\n",
        "    'Receiver_bank_location_India':0,\n",
        "    'Receiver_bank_location_Italy':0,\n",
        "    'Receiver_bank_location_Japan':0,\n",
        "    'Receiver_bank_location_Mexico':0,\n",
        "    'Receiver_bank_location_Morocco':0,\n",
        "    'Receiver_bank_location_Netherlands':0,\n",
        "    'Receiver_bank_location_Nigeria':0,\n",
        "    'Receiver_bank_location_Pakistan':0,\n",
        "    'Receiver_bank_location_Spain':0,\n",
        "    'Receiver_bank_location_Switzerland':0,\n",
        "    'Receiver_bank_location_Turkey':0,\n",
        "    'Receiver_bank_location_UAE':0,\n",
        "    'Receiver_bank_location_UK':0,\n",
        "    'Receiver_bank_location_USA':0,\n",
        "    'Payment_type_ACH':0,\n",
        "    'Payment_type_Cash Deposit':0,\n",
        "    'Payment_type_Cash Withdrawal':0,\n",
        "    'Payment_type_Cheque':0,\n",
        "    'Payment_type_Credit card':0,\n",
        "    'Payment_type_Cross-border':1,\n",
        "    'Payment_type_Debit card':0,\n",
        "    'Laundering_type_Behavioural_Change_1':0,\n",
        "    'Laundering_type_Behavioural_Change_2':1,\n",
        "    'Laundering_type_Bipartite':1,\n",
        "    'Laundering_type_Cash_Withdrawal':0,\n",
        "    'Laundering_type_Cycle':0,\n",
        "    'Laundering_type_Deposit-Send':0,\n",
        "    'Laundering_type_Fan_In':0,\n",
        "    'Laundering_type_Fan_Out':0,\n",
        "    'Laundering_type_Gather-Scatter':0,\n",
        "    'Laundering_type_Layered_Fan_In':0,\n",
        "    'Laundering_type_Layered_Fan_Out':0,\n",
        "    'Laundering_type_Normal_Cash_Deposits':0,\n",
        "    'Laundering_type_Normal_Cash_Withdrawal':0,\n",
        "    'Laundering_type_Normal_Fan_In':1,\n",
        "    'Laundering_type_Normal_Fan_Out':0,\n",
        "    'Laundering_type_Normal_Foward':0,\n",
        "    'Laundering_type_Normal_Group':0,\n",
        "    'Laundering_type_Normal_Mutual':0,\n",
        "    'Laundering_type_Normal_Periodical':0,\n",
        "    'Laundering_type_Normal_Plus_Mutual':0,\n",
        "    'Laundering_type_Normal_Small_Fan_Out':0,\n",
        "    'Laundering_type_Normal_single_large':0,\n",
        "    'Laundering_type_Scatter-Gather':0,\n",
        "    'Laundering_type_Single_large':0,\n",
        "    'Laundering_type_Smurfing':0,\n",
        "    'Laundering_type_Stacked Bipartite':0,\n",
        "    'Laundering_type_Structuring':0,         # Replace with actual values as per your dataset\n",
        "    'high_risk_countries': 0\n",
        "}\n"
      ],
      "metadata": {
        "id": "Yi5calopJxTA"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "risk_score, reduced_features = process_features_and_calculate_risk(features)\n",
        "print(\"Risk Score:\", risk_score)\n",
        "print(\"Reduced Features:\", reduced_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijsyosL6J07E",
        "outputId": "2df7de9c-a7a9-4bfa-ef05-89e4ef5b55e9"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 121ms/step\n",
            "Risk Score: 1.0\n",
            "Reduced Features: [ 4.993172   5.790073  14.401524   3.2185137  0.3269629  4.0952272\n",
            "  0.         4.858855 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SffCWCRki0ds"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}